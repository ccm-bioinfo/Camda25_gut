{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5864ecc-abbd-4e61-85ea-c3e23264b61c",
   "metadata": {},
   "source": [
    "# KS - hiPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a2699-3755-4dbf-ad2b-9b64e337cb2b",
   "metadata": {},
   "source": [
    "In this notebook we replicate the Kolgomorov-Smirnov hiPCA index as described in (Zhu et al, 2023). We also capture all the experiments made in pursue to obtain the best result for the CAMDA 2024 challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ef32ee-18d3-4671-a612-670b2c066399",
   "metadata": {},
   "source": [
    "First we import the necessary libraries to run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9e383c3-c1cf-4180-9c50-096666e7e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kstest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import chi2, norm\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e080d4-f449-49a0-9f68-797369460a87",
   "metadata": {},
   "source": [
    "Now we need to read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89073018-d9fa-4f2d-afa3-a7c33f3d196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = pd.read_csv('../../DataSets/CAMDA/taxonomy.txt', sep = '\\t', index_col = 0)\n",
    "metadata = pd.read_csv('../../DataSets/CAMDA/metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd179fff-2d39-4187-9647-6da36dc14d00",
   "metadata": {},
   "source": [
    "We select the samples which have most of the species identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "63111223-b8a7-47d3-b4dc-9f1f5f8bc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples = []\n",
    "for c in taxonomy.columns:\n",
    "    if sum(taxonomy[c]) > 90:\n",
    "        good_samples.append(c)\n",
    "taxonomy_aux = taxonomy[good_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3ad94-1354-4524-8eb4-054b48de0dfc",
   "metadata": {},
   "source": [
    "From previous experiments we obtained better performance taking out the samples labeled as Obese, that is the reason we are not going to consider them either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87131074-a469-4799-83c3-f67f35b1345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obese = list(metadata[metadata['Diagnosis'] == 'Obese']['SampleID'])\n",
    "healthy = list(metadata[metadata['Diagnosis'] == 'Healthy']['SampleID'])\n",
    "non_healthy = list(metadata[metadata['Diagnosis'] != 'Healthy']['SampleID'])\n",
    "non_healthy = [x for x in non_healthy if x not in obese]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6dd072-7490-4606-87ca-3da836117a89",
   "metadata": {},
   "source": [
    "Next we will define a function to perform Kolmogorov-Smirnov test to find the most important features for the PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "828a2d19-2959-47ca-af78-46314590ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_test(df, healthy, non_healthy, method_ks = 'auto', p_val = 0.001):\n",
    "    healthy_df = df[[x for x in df.columns if x in healthy]].T\n",
    "    nonhealthy_df = df[[x for x in df.columns if x in non_healthy]].T\n",
    "    healthy_features = []\n",
    "    nonhealthy_features = []\n",
    "    for feature in list(df.index):\n",
    "        if kstest(list(healthy_df[feature]), list(nonhealthy_df[feature]), alternative = 'less', method = method_ks).pvalue <= p_val:\n",
    "            healthy_features.append(feature)\n",
    "        if kstest(list(nonhealthy_df[feature]), list(healthy_df[feature]), alternative = 'less', method = method_ks).pvalue <= p_val:\n",
    "            nonhealthy_features.append(feature)\n",
    "    print(f'# Healthy features selected by KS: {len(healthy_features)}')\n",
    "    print(f'# Unheatlhy features selected by KS: {len(nonhealthy_features)}')\n",
    "    return healthy_features, nonhealthy_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c668f8a0-9290-48e6-9862-297221d13190",
   "metadata": {},
   "source": [
    "Now we define the data preprocessing workflow as defined in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5a7d34ed-758d-440a-a89d-d53533afcf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transform(x):\n",
    "    if x <= 1:\n",
    "        return np.log2(2 * x + 0.00001)\n",
    "    else:\n",
    "        return np.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a053da7-699f-4755-b013-28e2d1f111d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, healthy_features, nonhealthy_features):\n",
    "    scaler = StandardScaler()\n",
    "    selected = df.T[[x for x in list(set(healthy_features + nonhealthy_features)) if x in df.T.columns]]\n",
    "    selected = selected.applymap(custom_transform)\n",
    "\n",
    "    for c in selected.columns:\n",
    "        scaler.fit(np.array(selected[c]).reshape(-1, 1))\n",
    "        selected[c] = scaler.transform(np.array(selected[c]).reshape(-1, 1))\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe03c66-151c-4256-a3f0-fb0b399c7006",
   "metadata": {},
   "source": [
    "Then we define a function to perform PCA over the selected features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "40be3c08-1694-44c2-a4fe-a7f58b57e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_data(df):\n",
    "    pca = PCA()\n",
    "\n",
    "    pca.fit(df)\n",
    "\n",
    "    eigenvalues = pca.explained_variance_\n",
    "    eigenvectors = pca.components_\n",
    "    singular = pca.singular_values_\n",
    "    \n",
    "    pca_data = pd.DataFrame(zip(eigenvectors, eigenvalues, singular), columns = ('Eigenvectors', 'Explained_variance', 'Singular_values')).sort_values('Explained_variance', ascending = False)\n",
    "    pca_data['%variance'] = pca_data['Explained_variance'] / sum(pca_data['Explained_variance'])\n",
    "    pca_data = pca_data.sort_values('%variance', ascending = False)\n",
    "    pca_data['%variance_cumulative'] = pca_data['%variance'].cumsum()\n",
    "    \n",
    "    return pca_data, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3eba2e-5fa6-4da4-9ec1-447bc105bebf",
   "metadata": {},
   "source": [
    "After that we start calculating the indexes, below there is a function to calculate T^2 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8097c8a6-aa01-4f2e-9c3a-0ce8b2e5cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotelling_t2(df, pca, pca_data, variance_for_pc = 0.9, alpha = 0.05):\n",
    "    principal_components = list(pca_data[pca_data['%variance_cumulative'] < variance_for_pc]['Eigenvectors'])\n",
    "    print(f'# Principal Components selected: {len(principal_components)}')\n",
    "    principal_values = list(pca_data[pca_data['%variance_cumulative'] < variance_for_pc]['Explained_variance'])\n",
    "    D = np.array(principal_components).T @ np.linalg.inv(np.diag(principal_values)) @ np.array(principal_components)\n",
    "    deg_free = len(principal_components) \n",
    "    # alpha = 0.05\n",
    "    t2_threshold = chi2.ppf(1-alpha, deg_free)\n",
    "    T2 = []\n",
    "    pred = []\n",
    "    \n",
    "    try:\n",
    "        for item in pca.transform(df):\n",
    "            index = item.T @ D @ item\n",
    "            T2.append(index)\n",
    "            if index > t2_threshold:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "    except:\n",
    "        for item in np.array(df):\n",
    "            index = item.T @ D @ item\n",
    "            T2.append(index)\n",
    "            if index > t2_threshold:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "            \n",
    "    hoteling = pd.DataFrame(zip(df.index, T2, pred), columns = ['Sample', 'T2', 'Prediction T2'])\n",
    "    \n",
    "    return D, principal_components, hoteling, t2_threshold\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a468de2-a6d2-4961-9fbd-3a1842021f5a",
   "metadata": {},
   "source": [
    "Here we made a modification to Q_statistic limit according to ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82d33df9-c69e-430c-8f53-77f54afe7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_statistic(df, pca, pca_data, variance_for_pc = 0.9, alpha = 0.05):\n",
    "    principal_components_residual = list(pca_data[pca_data['%variance_cumulative'] >= variance_for_pc]['Eigenvectors'])\n",
    "    principal_values_residual = list(pca_data[pca_data['%variance_cumulative'] >= variance_for_pc]['Explained_variance'])\n",
    "    principal_singvalues_residual = list(pca_data[pca_data['%variance_cumulative'] >= variance_for_pc]['Singular_values'])\n",
    "    \n",
    "    C = np.array(principal_components_residual).T @ np.array(principal_components_residual)\n",
    "    Theta1 = sum(principal_values_residual)\n",
    "    Theta2 = sum([x**2 for x in principal_values_residual])\n",
    "    Theta3 = sum([x**3 for x in principal_values_residual])\n",
    "    \n",
    "    c_alpha = norm.ppf(1-alpha)\n",
    "    \n",
    "    h0 = 1-((2*Theta1*Theta3)/(3*Theta2**2))\n",
    "    \n",
    "    Q_alpha = Theta1*(((((c_alpha*np.sqrt(2*Theta2*(h0**2)))/Theta1)+1+((Theta2*h0*(h0-1))/(Theta1**2))))**(1/h0))\n",
    "    \n",
    "    Q = []\n",
    "    pred = []\n",
    "    try:\n",
    "        for item in pca.transform(df):\n",
    "            index = item.T @ C @ item\n",
    "            Q.append(index)\n",
    "            if index > Q_alpha:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "    except:\n",
    "        for item in np.array(df):\n",
    "            index = item.T @ C @ item\n",
    "            Q.append(index)\n",
    "            if index > Q_alpha:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "    \n",
    "    Q_statistic = pd.DataFrame(zip(df.index, Q, pred), columns = ['Sample', 'Q', 'Prediction Q'])\n",
    "    \n",
    "    return C, Theta1, Theta2, Q_statistic, Q_alpha\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1fec9f2-826c-412f-b6b7-c5670a506c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_index(df, D, t2_threshold, principal_components, Q_alpha, Theta1, Theta2, pca, alpha = 0.05):\n",
    "    fi = D/t2_threshold + (np.eye(len(principal_components[0])) - (np.array(principal_components).T @ np.array(principal_components)))/Q_alpha\n",
    "    g = ((len(principal_components) / t2_threshold**2) + (Theta2 / Q_alpha**2)) / ((len(principal_components)/t2_threshold) + (Theta1 / Q_alpha))\n",
    "    h = ((len(principal_components)/t2_threshold) + (Theta1 / Q_alpha))**2 / ((len(principal_components) / t2_threshold**2) + (Theta2 / Q_alpha**2))\n",
    "\n",
    "    chi_value = chi2.ppf(1-alpha, h)\n",
    "    threshold_combined = g*chi_value\n",
    "    combined = []\n",
    "    pred = []\n",
    "    \n",
    "    try:\n",
    "        for item in pca.transform(df):\n",
    "            index = item.T @ fi @ item\n",
    "            combined.append(index)\n",
    "            if index > threshold_combined:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "    except:\n",
    "        for item in np.array(df):\n",
    "            index = item.T @ fi @ item\n",
    "            combined.append(index)\n",
    "            if index > threshold_combined:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "\n",
    "    combined = pd.DataFrame(zip(df.index, combined, pred), columns = ['Sample', 'Combined', 'Prediction Combined']) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4760ab-e28a-4fc0-ab21-c6532c93e8e2",
   "metadata": {},
   "source": [
    "Finally we define a function to calculate the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e8b6a66-e6ff-4fad-8e53-d67fac6bf480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hiPCA(df, healthy, non_health, df_ks = [], healthy_features = [], non_healthy_features = [], ks = False, method = 'auto', p_val = 0.001, only_nonhealthy_features = False):\n",
    "    if ks:\n",
    "        healthy_features, non_healthy_features = ks_test(df_ks, healthy, non_healthy, method_ks = method, p_val = p_val)\n",
    "        \n",
    "    if only_nonhealthy_features: \n",
    "        selected = transform_data(df, [], non_healthy_features)\n",
    "    else:\n",
    "        selected = transform_data(df, healthy_features, non_healthy_features)\n",
    "        \n",
    "    pca_data, pca = get_pca_data(selected)\n",
    "    D, principal_components, results_hotelling, t2_threshold = hotelling_t2(selected, pca, pca_data)\n",
    "    C, Theta1, Theta2, results_q, Q_alpha = Q_statistic(selected, pca, pca_data)\n",
    "    hiPCA = combined_index(selected, D, t2_threshold, principal_components, Q_alpha, Theta1, Theta2, pca)\n",
    "    \n",
    "    return healthy_features, non_healthy_features, pd.concat([results_hotelling, results_q.drop('Sample', axis = 1),  hiPCA.drop('Sample', axis = 1)], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ae9111-d121-4919-b899-99adef354f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc9266cb-641c-4471-96ff-305d483fce7b",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66719489-6b10-4d5d-81b3-0ea08e5c88de",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8cc75a-137a-4465-bc2c-d4b7c76487ef",
   "metadata": {},
   "source": [
    "First we will calculate KS-hiPCA index to the trainning data and evaluate its result using balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c06379b3-de57-4ee3-85dd-a1fd84b670e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Healthy features selected by KS: 140\n",
      "# Unheatlhy features selected by KS: 22\n",
      "# Principal Components selected: 15\n"
     ]
    }
   ],
   "source": [
    "healthy_features, non_healthy_features, results = hiPCA(taxonomy, healthy, non_healthy, df_ks = taxonomy_aux, ks = True, only_nonhealthy_features = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a7a44a6-4cd0-45c5-bbfe-4a042b6640f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_hiPCA = balanced_accuracy_score(['Unhealthy' if x != 'Healthy' else 'Healthy' for x in metadata[metadata['SampleID'].isin(taxonomy.columns)]['Diagnosis']], ['Unhealthy' if x > 3.8 else 'Healthy' for x in metadata['hiPCA']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4cf825be-fc19-44b5-93bf-4e8dc798f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_hiPCA = balanced_accuracy_score(['Unhealthy' if x != 'Healthy' else 'Healthy' for x in metadata[metadata['SampleID'].isin(taxonomy.columns)]['Diagnosis']],results['Prediction Combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "091dc65b-55ea-4732-9b29-b1ff3e9618ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_hiPCA = balanced_accuracy_score(['Unhealthy' if x != 'Healthy' else 'Healthy' for x in metadata[metadata['SampleID'].isin(taxonomy.columns)]['Diagnosis']],results['Prediction T2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de5282de-0949-4ffe-a1b5-543534bb6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_hiPCA = balanced_accuracy_score(['Unhealthy' if x != 'Healthy' else 'Healthy' for x in metadata[metadata['SampleID'].isin(taxonomy.columns)]['Diagnosis']],results['Prediction Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "893056b0-0786-4124-9626-4bc6ee2e8a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given hiPCA: 0.6726198083067092\n",
      "KS - hiPCA (T^2) : 0.666038338658147\n",
      "KS - hiPCA (Q) : 0.6999787007454739\n",
      "KS - hiPCA (Combined): 0.7498509052183173\n"
     ]
    }
   ],
   "source": [
    "print(f'Given hiPCA: {original_hiPCA}')\n",
    "print(f'KS - hiPCA (T^2) : {t2_hiPCA}')\n",
    "print(f'KS - hiPCA (Q) : {q_hiPCA}')\n",
    "print(f'KS - hiPCA (Combined): {ks_hiPCA}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18176574-a53a-4e6e-bdd9-ba0f6a0164ac",
   "metadata": {},
   "source": [
    ">Note that we did not have the threshold for the given hiPCA to classify samples, we arbitrarly chose the threshold that gave best result to make a fair comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd95bc5-2082-4254-a322-ce0d242a1e6f",
   "metadata": {},
   "source": [
    "Now we will use this model to try to predict the unhealthy samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cd9c4cf9-3e63-427e-b60b-c34f4dfc2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_covid = pd.read_csv('../../DataSets/COVID/CAMDA_taxa.txt', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10035fd7-646a-4af1-890f-fba093be104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Principal Components selected: 10\n"
     ]
    }
   ],
   "source": [
    "_, _, results_covid_taxonomy = hiPCA(taxonomy_covid, [], [], non_healthy_features = non_healthy_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fd2c71e7-7578-47b5-9152-92d8728b2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_covid_taxonomy.to_csv('../../output/hiPCA/kshiPCA_covid_taxonomy.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d47d8-c73d-452f-8d0f-5aba37a7b136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33a02427-3bbd-487a-be13-e73ec8e4b86d",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c4f6aaec-cdcb-4133-8d80-2ecafcef66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unhealthy_tax = pd.read_csv('../../DataSets/INDEX/hiPCA/zhu_ks92_unhealthy_species.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "894b3fe4-dff3-455c-9557-3fb4349dc069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Principal Components selected: 35\n"
     ]
    }
   ],
   "source": [
    "healthy_features, non_healthy_features, results = hiPCA(taxonomy, healthy, non_healthy, non_healthy_features = list(unhealthy_tax['species']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9d66333b-ad6f-4883-afcd-c441df4cd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiPCA_zhutax = balanced_accuracy_score(['Unhealthy' if x != 'Healthy' else 'Healthy' for x in metadata[metadata['SampleID'].isin(taxonomy.columns)]['Diagnosis']],results['Prediction Combined'])\n",
    "hiPCA_zhutax_t2 = balanced_accuracy_score(['Unhealthy' if x != 'Healthy' else 'Healthy' for x in metadata[metadata['SampleID'].isin(taxonomy.columns)]['Diagnosis']],results['Prediction T2'])\n",
    "hiPCA_zhutax_q = balanced_accuracy_score(['Unhealthy' if x != 'Healthy' else 'Healthy' for x in metadata[metadata['SampleID'].isin(taxonomy.columns)]['Diagnosis']],results['Prediction Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0a86fefd-8da8-4254-b361-f41a98149709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given hiPCA: 0.6726198083067092\n",
      "hiPCA with Zhu taxa (T^2): 0.5877742279020234\n",
      "hiPCA with Zhu taxa (Q): 0.6293503727369542\n",
      "hiPCA with Zhu taxa (Combined): 0.647555910543131\n"
     ]
    }
   ],
   "source": [
    "print(f'Given hiPCA: {original_hiPCA}')\n",
    "print(f'hiPCA with Zhu taxa (T^2): {hiPCA_zhutax_t2}')\n",
    "print(f'hiPCA with Zhu taxa (Q): {hiPCA_zhutax_q}')\n",
    "print(f'hiPCA with Zhu taxa (Combined): {hiPCA_zhutax}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ea7d7a70-140e-4027-9650-37adfa2fb37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Principal Components selected: 15\n"
     ]
    }
   ],
   "source": [
    "_, _, results_covid_taxonomy = hiPCA(taxonomy_covid, [], [], non_healthy_features = list(unhealthy_tax['species']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d87300f-299d-4005-bf92-35997bcc7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_covid_taxonomy.to_csv('../../output/hiPCA/hiPCAzhutax_covid.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda0eee-88ab-4382-a819-9831f5087406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12d18c63-df7d-4e59-8ffe-70ad226a4d18",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4247010e-ee1c-4fa3-80ac-de0ea2fca7ca",
   "metadata": {},
   "source": [
    "Now we tried to fit pathways data to the KS - hiPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4f57a03d-c840-4826-8aa6-08ec66cfd4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways = pd.read_csv('../../DataSets/CAMDA/pathways.txt', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c0872116-ef54-41a0-a4e5-178f47696113",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways = pathways.T[[x for x in pathways.index if 'UNINTEGRATED' not in x]]\n",
    "pathways = pathways.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5675d7f2-20db-420c-ba22-01ef73d9a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples = []\n",
    "for c in taxonomy.columns:\n",
    "    if sum(taxonomy[c]) > 90:\n",
    "        good_samples.append(c)\n",
    "pathways_aux = pathways[good_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "44b80a21-a512-4aab-a532-38b0c35a25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = list(metadata[metadata['Diagnosis'] == 'Obese']['SampleID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2b817490-9c23-4a8c-9b25-a75d7482c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy = list(metadata[metadata['Diagnosis'] == 'Healthy']['SampleID'])\n",
    "non_healthy = list(metadata[metadata['Diagnosis'] != 'Healthy']['SampleID'])\n",
    "non_healthy = [x for x in non_healthy if x not in ob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "035be7b5-8858-482d-992c-ae64c0476433",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_healthy = pathways[[x for x in pathways_aux.columns if x in healthy]].T\n",
    "pathways_nonhealthy = pathways[[x for x in pathways_aux.columns if x in non_healthy]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f22e2468-d7b1-4926-9ed7-374a2d026841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Healthy features selected by KS: 1103\n",
      "# Unheatlhy features selected by KS: 770\n",
      "# Principal Components selected: 28\n"
     ]
    }
   ],
   "source": [
    "healthy_features, non_healthy_features, results_pathways = hiPCA(pathways, healthy, non_healthy, df_ks = pathways_aux, ks = True, only_nonhealthy_features = False, method = 'asymp', p_val = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "947acc0d-93a5-41b2-98b1-71ffddd1ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_hiPCA_path = balanced_accuracy_score(['Unhealthy' if x != 'Healthy' else 'Healthy' for x in metadata[metadata['SampleID'].isin(taxonomy.columns)]['Diagnosis']],results_pathways['Prediction Combined'])\n",
    "ks_hiPCA_patht2 = balanced_accuracy_score(['Unhealthy' if x != 'Healthy' else 'Healthy' for x in metadata[metadata['SampleID'].isin(taxonomy.columns)]['Diagnosis']],results_pathways['Prediction T2'])\n",
    "ks_hiPCA_pathq = balanced_accuracy_score(['Unhealthy' if x != 'Healthy' else 'Healthy' for x in metadata[metadata['SampleID'].isin(taxonomy.columns)]['Diagnosis']],results_pathways['Prediction Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "17fe688e-77d7-4cc8-b3e4-92f139939371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given hiPCA: 0.6726198083067092\n",
      "hiPCA with pathways (T^2): 0.6078434504792332\n",
      "hiPCA with pathways (Q): 0.512321618743344\n",
      "hiPCA with pathways (Combined): 0.6063099041533546\n"
     ]
    }
   ],
   "source": [
    "print(f'Given hiPCA: {original_hiPCA}')\n",
    "print(f'hiPCA with pathways (T^2): {ks_hiPCA_patht2}')\n",
    "print(f'hiPCA with pathways (Q): {ks_hiPCA_pathq}')\n",
    "print(f'hiPCA with pathways (Combined): {ks_hiPCA_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b8a5b-8ad9-4b19-bf7a-93b7698bd2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dff17cd0-80ea-4ccd-996d-b79213befdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_covid = pd.read_csv('../../DataSets/COVID/CAMDA_pathways.txt', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a2c86528-1c00-4baf-99c5-40aac821d749",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [111]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _, _, results_hotelling_covid, results_q_covid, results_hiPCA_covid \u001b[38;5;241m=\u001b[39m \u001b[43mhiPCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathways_covid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhealthy_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhealthy_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_healthy_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnon_healthy_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36mhiPCA\u001b[1;34m(df, healthy, non_health, df_ks, healthy_features, non_healthy_features, ks, method, p_val, only_nonhealthy_features)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     selected \u001b[38;5;241m=\u001b[39m transform_data(df, healthy_features, non_healthy_features)\n\u001b[1;32m---> 10\u001b[0m pca_data, pca \u001b[38;5;241m=\u001b[39m \u001b[43mget_pca_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m D, principal_components, results_hotelling, t2_threshold \u001b[38;5;241m=\u001b[39m hotelling_t2(selected, pca, pca_data)\n\u001b[0;32m     12\u001b[0m C, Theta1, Theta2, results_q, Q_alpha \u001b[38;5;241m=\u001b[39m Q_statistic(selected, pca, pca_data)\n",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36mget_pca_data\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_pca_data\u001b[39m(df):\n\u001b[0;32m      2\u001b[0m     pca \u001b[38;5;241m=\u001b[39m PCA()\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     eigenvalues \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mexplained_variance_\n\u001b[0;32m      7\u001b[0m     eigenvectors \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mcomponents_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:408\u001b[0m, in \u001b[0;36mPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    401\u001b[0m check_scalar(\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_oversamples,\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_oversamples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    404\u001b[0m     min_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    405\u001b[0m     target_type\u001b[38;5;241m=\u001b[39mnumbers\u001b[38;5;241m.\u001b[39mIntegral,\n\u001b[0;32m    406\u001b[0m )\n\u001b[1;32m--> 408\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:456\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA does not support sparse input. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTruncatedSVD for a possible alternative.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m     )\n\u001b[1;32m--> 456\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:768\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    764\u001b[0m     pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    765\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[0;32m    766\u001b[0m     )\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 768\u001b[0m         dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric:\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dtype_orig\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    772\u001b[0m         \u001b[38;5;66;03m# if input is object, convert to float.\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "_, _, results_hotelling_covid, results_q_covid, results_hiPCA_covid = hiPCA(pathways_covid, [], [], healthy_features = healthy_features, non_healthy_features = non_healthy_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b617c1-c8ac-412e-a689-09ea796891dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
