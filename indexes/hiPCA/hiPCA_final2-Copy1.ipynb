{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5864ecc-abbd-4e61-85ea-c3e23264b61c",
   "metadata": {},
   "source": [
    "# KS - hiPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a2699-3755-4dbf-ad2b-9b64e337cb2b",
   "metadata": {},
   "source": [
    "In this notebook we replicate the Kolgomorov-Smirnov hiPCA index as described in (Zhu et al, 2023). We also capture all the experiments made in pursue to obtain the best result for the CAMDA 2024 challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ef32ee-18d3-4671-a612-670b2c066399",
   "metadata": {},
   "source": [
    "First we import the necessary libraries to run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b6ae7ae1-547c-4868-80e9-8feb4dec0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c9e383c3-c1cf-4180-9c50-096666e7e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kstest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import chi2, norm\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e080d4-f449-49a0-9f68-797369460a87",
   "metadata": {},
   "source": [
    "Now we need to read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "89073018-d9fa-4f2d-afa3-a7c33f3d196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = pd.read_csv('../../DataSets/CAMDA/taxonomy.txt', sep = '\\t', index_col = 0)\n",
    "metadata = pd.read_csv('../../DataSets/CAMDA/metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd179fff-2d39-4187-9647-6da36dc14d00",
   "metadata": {},
   "source": [
    "We select the samples which have most of the species identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "63111223-b8a7-47d3-b4dc-9f1f5f8bc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples = []\n",
    "for c in taxonomy.columns:\n",
    "    if sum(taxonomy[c]) > 90:\n",
    "        good_samples.append(c)\n",
    "taxonomy_aux = taxonomy[good_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3ad94-1354-4524-8eb4-054b48de0dfc",
   "metadata": {},
   "source": [
    "From previous experiments we obtained better performance taking out the samples labeled as Obese, that is the reason we are not going to consider them either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "87131074-a469-4799-83c3-f67f35b1345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obese = list(metadata[metadata['Diagnosis'] == 'Obese']['SampleID'])\n",
    "healthy = list(metadata[metadata['Diagnosis'] == 'Healthy']['SampleID'])\n",
    "non_healthy = list(metadata[metadata['Diagnosis'] != 'Healthy']['SampleID'])\n",
    "non_healthy = [x for x in non_healthy if x not in obese]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6dd072-7490-4606-87ca-3da836117a89",
   "metadata": {},
   "source": [
    "Next we will define a function to perform Kolmogorov-Smirnov test to find the most important features for the PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "828a2d19-2959-47ca-af78-46314590ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_test(df, healthy, non_healthy, method_ks = 'auto', p_val = 0.001):\n",
    "    healthy_df = df[[x for x in df.columns if x in healthy]].T\n",
    "    nonhealthy_df = df[[x for x in df.columns if x in non_healthy]].T\n",
    "    healthy_features = []\n",
    "    nonhealthy_features = []\n",
    "    for feature in list(df.index):\n",
    "        if kstest(list(healthy_df[feature]), list(nonhealthy_df[feature]), alternative = 'less', method = method_ks).pvalue <= p_val:\n",
    "            healthy_features.append(feature)\n",
    "        if kstest(list(nonhealthy_df[feature]), list(healthy_df[feature]), alternative = 'less', method = method_ks).pvalue <= p_val:\n",
    "            nonhealthy_features.append(feature)\n",
    "    print(f'# Healthy features selected by KS: {len(healthy_features)}')\n",
    "    print(f'# Unheatlhy features selected by KS: {len(nonhealthy_features)}')\n",
    "    return healthy_features, nonhealthy_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c668f8a0-9290-48e6-9862-297221d13190",
   "metadata": {},
   "source": [
    "Now we define the data preprocessing workflow as defined in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5a7d34ed-758d-440a-a89d-d53533afcf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transform(x):\n",
    "    if x <= 1:\n",
    "        return np.log2(2 * x + 0.00001)\n",
    "    else:\n",
    "        return np.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6a053da7-699f-4755-b013-28e2d1f111d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, features):\n",
    "    scaler = StandardScaler()\n",
    "    # selected = df.T[[x for x in list(set(healthy_features + nonhealthy_features)) if x in df.T.columns]]\n",
    "    aux = pd.DataFrame()\n",
    "    for item in list(set(features)):\n",
    "        if item in df.index:\n",
    "            aux[item] = list(df.T[item])\n",
    "        else:\n",
    "            aux[item] = [0 for x in range(len(df.T))]\n",
    "    selected = aux.applymap(custom_transform)\n",
    "\n",
    "    for c in selected.columns:\n",
    "        scaler.fit(np.array(selected[c]).reshape(-1, 1))\n",
    "        selected[c] = scaler.transform(np.array(selected[c]).reshape(-1, 1))\n",
    "        \n",
    "    selected.index = df.T.index\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe03c66-151c-4256-a3f0-fb0b399c7006",
   "metadata": {},
   "source": [
    "Then we define a function to perform PCA over the selected features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "40be3c08-1694-44c2-a4fe-a7f58b57e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_data(df):\n",
    "    pca = PCA()\n",
    "\n",
    "    pca.fit(df)\n",
    "\n",
    "    eigenvalues = pca.explained_variance_\n",
    "    eigenvectors = pca.components_\n",
    "    singular = pca.singular_values_\n",
    "    \n",
    "    pca_data = pd.DataFrame(zip(eigenvectors, eigenvalues, singular), columns = ('Eigenvectors', 'Explained_variance', 'Singular_values')).sort_values('Explained_variance', ascending = False)\n",
    "    pca_data['%variance'] = pca_data['Explained_variance'] / sum(pca_data['Explained_variance'])\n",
    "    pca_data = pca_data.sort_values('%variance', ascending = False)\n",
    "    pca_data['%variance_cumulative'] = pca_data['%variance'].cumsum()\n",
    "    \n",
    "    return pca_data, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ab95cc0b-d78e-452f-a20c-371df89ce78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pca_stats(df, variance_for_pc = 0.9, alpha = 0.05):\n",
    "    pca = PCA()\n",
    "\n",
    "    pca.fit(df)\n",
    "\n",
    "    eigenvalues = pca.explained_variance_\n",
    "    eigenvectors = pca.components_\n",
    "    singular = pca.singular_values_\n",
    "    \n",
    "    pca_data = pd.DataFrame(zip(eigenvectors, eigenvalues, singular), columns = ('Eigenvectors', 'Explained_variance', 'Singular_values')).sort_values('Explained_variance', ascending = False)\n",
    "    pca_data['%variance'] = pca_data['Explained_variance'] / sum(pca_data['Explained_variance'])\n",
    "    pca_data = pca_data.sort_values('%variance', ascending = False)\n",
    "    pca_data['%variance_cumulative'] = pca_data['%variance'].cumsum()\n",
    "    \n",
    "    principal_components = list(pca_data[pca_data['%variance_cumulative'] < variance_for_pc]['Eigenvectors'])\n",
    "    print(f'# Principal Components selected: {len(principal_components)}')\n",
    "    \n",
    "    principal_values = list(pca_data[pca_data['%variance_cumulative'] < variance_for_pc]['Explained_variance'])\n",
    "    D = np.array(principal_components).T @ np.linalg.inv(np.diag(principal_values)) @ np.array(principal_components)\n",
    "    deg_free = len(principal_components) \n",
    "    # alpha = 0.05\n",
    "    t2_threshold = chi2.ppf(1-alpha, deg_free)\n",
    "#     print(1-alpha, deg_free)\n",
    "#     print(t2_threshold)\n",
    "    \n",
    "    principal_components_residual = list(pca_data[pca_data['%variance_cumulative'] >= variance_for_pc]['Eigenvectors'])\n",
    "    principal_values_residual = list(pca_data[pca_data['%variance_cumulative'] >= variance_for_pc]['Explained_variance'])\n",
    "    principal_singvalues_residual = list(pca_data[pca_data['%variance_cumulative'] >= variance_for_pc]['Singular_values'])\n",
    "    \n",
    "    C = np.array(principal_components_residual).T @ np.array(principal_components_residual)\n",
    "    Theta1 = sum(principal_values_residual)\n",
    "    Theta2 = sum([x**2 for x in principal_values_residual])\n",
    "    Theta3 = sum([x**3 for x in principal_values_residual])\n",
    "    \n",
    "    c_alpha = norm.ppf(1-alpha)\n",
    "    \n",
    "    h0 = 1-((2*Theta1*Theta3)/(3*Theta2**2))\n",
    "    \n",
    "    Q_alpha = Theta1*(((((c_alpha*np.sqrt(2*Theta2*(h0**2)))/Theta1)+1+((Theta2*h0*(h0-1))/(Theta1**2))))**(1/h0))\n",
    "    \n",
    "    fi = D/t2_threshold + (np.eye(len(principal_components[0])) - (np.array(principal_components).T @ np.array(principal_components)))/Q_alpha\n",
    "    g = ((len(principal_components) / t2_threshold**2) + (Theta2 / Q_alpha**2)) / ((len(principal_components)/t2_threshold) + (Theta1 / Q_alpha))\n",
    "    h = ((len(principal_components)/t2_threshold) + (Theta1 / Q_alpha))**2 / ((len(principal_components) / t2_threshold**2) + (Theta2 / Q_alpha**2))\n",
    "\n",
    "    chi_value = chi2.ppf(1-alpha, h)\n",
    "    threshold_combined = g*chi_value\n",
    "    \n",
    "    return pca, pca_data, D, t2_threshold, C, Q_alpha, fi, threshold_combined\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "462561b4-17e9-4e9b-893e-5f65e1f18697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(pca, samples_df):\n",
    "    for item in pca.transform(samples_df):\n",
    "        index = item.T @ D @ item\n",
    "        T2.append(index)\n",
    "        if index > t2_threshold:\n",
    "            pred.append('Unhealthy')\n",
    "        else:\n",
    "            pred.append('Healthy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3eba2e-5fa6-4da4-9ec1-447bc105bebf",
   "metadata": {},
   "source": [
    "After that we start calculating the indexes, below there is a function to calculate T^2 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8097c8a6-aa01-4f2e-9c3a-0ce8b2e5cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotelling_t2(df, pca, pca_data, variance_for_pc = 0.9, alpha = 0.05):\n",
    "    principal_components = list(pca_data[pca_data['%variance_cumulative'] < variance_for_pc]['Eigenvectors'])\n",
    "    print(f'# Principal Components selected: {len(principal_components)}')\n",
    "    principal_values = list(pca_data[pca_data['%variance_cumulative'] < variance_for_pc]['Explained_variance'])\n",
    "    D = np.array(principal_components).T @ np.linalg.inv(np.diag(principal_values)) @ np.array(principal_components)\n",
    "    deg_free = len(principal_components) \n",
    "    # alpha = 0.05\n",
    "    t2_threshold = chi2.ppf(1-alpha, deg_free)\n",
    "    T2 = []\n",
    "    pred = []\n",
    "    \n",
    "    try:\n",
    "        for item in pca.transform(df):\n",
    "            index = item.T @ D @ item\n",
    "            T2.append(index)\n",
    "            if index > t2_threshold:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "    except:\n",
    "        for item in np.array(df):\n",
    "            index = item.T @ D @ item\n",
    "            T2.append(index)\n",
    "            if index > t2_threshold:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "            \n",
    "    hoteling = pd.DataFrame(zip(df.index, T2, pred), columns = ['Sample', 'T2', 'Prediction T2'])\n",
    "    \n",
    "    return D, principal_components, hoteling, t2_threshold\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a468de2-a6d2-4961-9fbd-3a1842021f5a",
   "metadata": {},
   "source": [
    "Here we made a modification to Q_statistic limit according to ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "82d33df9-c69e-430c-8f53-77f54afe7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_statistic(df, pca, pca_data, variance_for_pc = 0.9, alpha = 0.05):\n",
    "    principal_components_residual = list(pca_data[pca_data['%variance_cumulative'] >= variance_for_pc]['Eigenvectors'])\n",
    "    principal_values_residual = list(pca_data[pca_data['%variance_cumulative'] >= variance_for_pc]['Explained_variance'])\n",
    "    principal_singvalues_residual = list(pca_data[pca_data['%variance_cumulative'] >= variance_for_pc]['Singular_values'])\n",
    "    \n",
    "    C = np.array(principal_components_residual).T @ np.array(principal_components_residual)\n",
    "    Theta1 = sum(principal_values_residual)\n",
    "    Theta2 = sum([x**2 for x in principal_values_residual])\n",
    "    Theta3 = sum([x**3 for x in principal_values_residual])\n",
    "    \n",
    "    c_alpha = norm.ppf(1-alpha)\n",
    "    \n",
    "    h0 = 1-((2*Theta1*Theta3)/(3*Theta2**2))\n",
    "    \n",
    "    Q_alpha = Theta1*(((((c_alpha*np.sqrt(2*Theta2*(h0**2)))/Theta1)+1+((Theta2*h0*(h0-1))/(Theta1**2))))**(1/h0))\n",
    "    \n",
    "    Q = []\n",
    "    pred = []\n",
    "    try:\n",
    "        for item in pca.transform(df):\n",
    "            index = item.T @ C @ item\n",
    "            Q.append(index)\n",
    "            if index > Q_alpha:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "    except:\n",
    "        for item in np.array(df):\n",
    "            index = item.T @ C @ item\n",
    "            Q.append(index)\n",
    "            if index > Q_alpha:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "    \n",
    "    Q_statistic = pd.DataFrame(zip(df.index, Q, pred), columns = ['Sample', 'Q', 'Prediction Q'])\n",
    "    \n",
    "    return C, Theta1, Theta2, Q_statistic, Q_alpha\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b1fec9f2-826c-412f-b6b7-c5670a506c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_index(df, D, t2_threshold, principal_components, Q_alpha, Theta1, Theta2, pca, alpha = 0.05):\n",
    "    fi = D/t2_threshold + (np.eye(len(principal_components[0])) - (np.array(principal_components).T @ np.array(principal_components)))/Q_alpha\n",
    "    g = ((len(principal_components) / t2_threshold**2) + (Theta2 / Q_alpha**2)) / ((len(principal_components)/t2_threshold) + (Theta1 / Q_alpha))\n",
    "    h = ((len(principal_components)/t2_threshold) + (Theta1 / Q_alpha))**2 / ((len(principal_components) / t2_threshold**2) + (Theta2 / Q_alpha**2))\n",
    "\n",
    "    chi_value = chi2.ppf(1-alpha, h)\n",
    "    threshold_combined = g*chi_value\n",
    "    combined = []\n",
    "    pred = []\n",
    "\n",
    "    try:\n",
    "        for item in pca.transform(df):\n",
    "            index = item.T @ fi @ item\n",
    "            combined.append(index)\n",
    "            if index > threshold_combined:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "    except:\n",
    "        for item in np.array(df):\n",
    "            index = item.T @ fi @ item\n",
    "            combined.append(index)\n",
    "            if index > threshold_combined:\n",
    "                pred.append('Unhealthy')\n",
    "            else:\n",
    "                pred.append('Healthy')\n",
    "\n",
    "    combined = pd.DataFrame(zip(df.index, combined, pred), columns = ['Sample', 'Combined', 'Prediction Combined']) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4760ab-e28a-4fc0-ab21-c6532c93e8e2",
   "metadata": {},
   "source": [
    "Finally we define a function to calculate the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d0393b68-7692-4596-915e-aae3af51eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hiPCA(df, healthy, non_healthy, features = [], ks = False, method = 'auto', p_val = 0.001, only_nonhealthy_features = False):\n",
    "    if ks:\n",
    "        healthy_features, non_healthy_features = ks_test(df, healthy, non_healthy, method_ks = method, p_val = p_val)\n",
    "        \n",
    "    if only_nonhealthy_features:\n",
    "        healthy_features = []\n",
    "        if ks:\n",
    "            features = healthy_features + non_healthy_features\n",
    "        selected = transform_data(df[[x for x in healthy if x in df.columns]], features)\n",
    "        \n",
    "    else:\n",
    "        if ks:\n",
    "            features = healthy_features + non_healthy_features\n",
    "        selected = transform_data(df[[x for x in healthy if x in df.columns]], features)\n",
    "    \n",
    "    # print(selected)\n",
    "    pca, pca_data, D, t2_threshold, C, Q_alpha, fi, threshold_combined = calculate_pca_stats(selected)\n",
    "    print(t2_threshold, Q_alpha, threshold_combined)\n",
    "\n",
    "        \n",
    "    return features, pca, pca_data, D, t2_threshold, C, Q_alpha, fi, threshold_combined, selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9971b-c242-4149-9959-d1ac645f5d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "51a555d8-6aec-49d2-9b3a-bb00de2ee1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_index(data_transformed):\n",
    "    T2, Q, combined = [], [], []\n",
    "    pred_t2, pred_Q, pred_combined = [], [], []\n",
    "\n",
    "    try:\n",
    "        for item in pca.transform(data_transformed):\n",
    "            index = item.T @ D @ item\n",
    "            index2 = item.T @ C @ item\n",
    "            index3 = item.T @ fi @ item\n",
    "            T2.append(index)\n",
    "            Q.append(index2)\n",
    "            combined.append(index3)\n",
    "            if index > t2_threshold:\n",
    "                pred_t2.append('Unhealthy')\n",
    "            else:\n",
    "                pred_t2.append('Healthy')\n",
    "\n",
    "            if index2 > Q_alpha:\n",
    "                pred_Q.append('Unhealthy')\n",
    "            else:\n",
    "                pred_Q.append('Healthy')\n",
    "\n",
    "            if index3 > threshold_combined:\n",
    "                pred_combined.append('Unhealthy')\n",
    "            else:\n",
    "                pred_combined.append('Healthy') \n",
    "    except:\n",
    "        for item in np.array(data_transformed):\n",
    "            index = item.T @ D @ item\n",
    "            index2 = item.T @ C @ item\n",
    "            index3 = item.T @ fi @ item\n",
    "            T2.append(index)\n",
    "            Q.append(index2)\n",
    "            combined.append(index3)\n",
    "            if index > t2_threshold:\n",
    "                pred_t2.append('Unhealthy')\n",
    "            else:\n",
    "                pred_t2.append('Healthy')\n",
    "\n",
    "            if index2 > Q_alpha:\n",
    "                pred_Q.append('Unhealthy')\n",
    "            else:\n",
    "                pred_Q.append('Healthy')\n",
    "\n",
    "            if index3 > threshold_combined:\n",
    "                pred_combined.append('Unhealthy')\n",
    "            else:\n",
    "                pred_combined.append('Healthy') \n",
    "\n",
    "    return pd.DataFrame(zip(data_transformed.index, T2, pred_t2, Q, pred_Q, combined, pred_combined), columns = ['SampleID', 'T2', 'Prediction T2', 'Q', 'Prediction Q', 'Combined Index', 'Combined Prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9266cb-641c-4471-96ff-305d483fce7b",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66719489-6b10-4d5d-81b3-0ea08e5c88de",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8cc75a-137a-4465-bc2c-d4b7c76487ef",
   "metadata": {},
   "source": [
    "First we will calculate KS-hiPCA index using just taxonomic profile with just the unhealthy related species evaluate its result using balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "9774238a-ce30-4357-8666-372e0f97978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obese = list(metadata[metadata['Diagnosis'] == 'Obese']['SampleID'])\n",
    "healthy = list(metadata[metadata['Diagnosis'] == 'Healthy']['SampleID'])\n",
    "non_healthy = list(metadata[metadata['Diagnosis'] != 'Healthy']['SampleID'])\n",
    "non_healthy = [x for x in non_healthy if x not in obese]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "384f5d10-831e-45cc-9078-6aa14889198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_not_obese = taxonomy_aux[[x for x in taxonomy_aux if x not in obese]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "71498fc0-e068-48d0-9367-abd66172b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_transposed = taxonomy_not_obese.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "eed98675-f507-460e-b836-abb78155edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for item in taxonomy_transposed.T.columns:\n",
    "    if metadata[metadata['SampleID'] == item]['Diagnosis'].iloc[0] == 'Healthy':\n",
    "        label.append('Healthy')\n",
    "    else:\n",
    "        label.append('Unhealthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "fd9bc2fc-7402-4b77-b22f-1fec552b26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(taxonomy_transposed, label, test_size=0.20, random_state=20, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d0a3268d-d57b-4d1f-9927-e2b87d4b9054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Healthy features selected by KS: 130\n",
      "# Unheatlhy features selected by KS: 17\n",
      "# Principal Components selected: 10\n",
      "0.95 10\n",
      "18.307038053275146\n",
      "18.307038053275146 4.198301915746644 1.6919901191461642\n"
     ]
    }
   ],
   "source": [
    "features, pca, pca_data, D, t2_threshold, C, Q_alpha, fi, threshold_combined, selected = hiPCA(X_train.T, healthy, non_healthy, ks = True, method = 'asymp', only_nonhealthy_features = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f9bc8b95-b719-419c-98d3-58c436e0f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = transform_data(X_test.T, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6e689187-452a-4286-b277-bad707e62647",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = calculate_index(test_transformed)\n",
    "# results.to_csv('../../output/hiPCA/experiment1_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "14c73fb8-57f3-488a-9aab-d2137b3fc1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS - hiPCA (T^2) : 0.7857142857142857\n",
      "KS - hiPCA (Q) : 0.6482263513513513\n",
      "KS - hiPCA (Combined): 0.8151913875598087\n"
     ]
    }
   ],
   "source": [
    "acc_combined = balanced_accuracy_score(results['Combined Prediction'], list(y_test))\n",
    "acc_t2 = balanced_accuracy_score(results['Prediction T2'], list(y_test))\n",
    "acc_q = balanced_accuracy_score(results['Prediction Q'], list(y_test))\n",
    "print(f'KS - hiPCA (T^2) : {acc_t2}')\n",
    "print(f'KS - hiPCA (Q) : {acc_q}')\n",
    "print(f'KS - hiPCA (Combined): {acc_combined}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "3387e679-ccaa-4d1b-905c-1d4821dc7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformed = transform_data(X_train.T, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "0fde9824-d09d-4ea2-9314-672f2454cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = calculate_index(train_transformed)\n",
    "# results.to_csv('../../output/hiPCA/experiment1_results_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b072a-36a8-4577-9c44-622b298d7977",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb348b3-1fee-4866-af8c-1a87ba510556",
   "metadata": {},
   "source": [
    "Now we will use the both the unhealthy and healhty species to build the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d0017598-123a-4793-b486-c3289de74c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Healthy features selected by KS: 130\n",
      "# Unheatlhy features selected by KS: 17\n",
      "# Principal Components selected: 51\n",
      "0.95 51\n",
      "68.66929391228578\n",
      "68.66929391228578 20.365473937778425 1.8419064612150686\n"
     ]
    }
   ],
   "source": [
    "features, pca, pca_data, D, t2_threshold, C, Q_alpha, fi, threshold_combined, selected = hiPCA(X_train.T, healthy, non_healthy, ks = True, method = 'asymp', only_nonhealthy_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "160c0f4a-830c-4969-849f-2b14162b374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = transform_data(X_test.T, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "26dd62e5-9bb1-432e-9b66-f996850be33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = calculate_index(test_transformed)\n",
    "# results.to_csv('../../output/hiPCA/experiment2_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c41d3b9a-70a2-4a2b-b04a-125abccb2c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48514851485148514"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(results['Combined Prediction'], list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f441d6d1-9228-40e1-9925-30c427357d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS - hiPCA (T^2) : 0.35\n",
      "KS - hiPCA (Q) : 0.48514851485148514\n",
      "KS - hiPCA (Combined): 0.48514851485148514\n"
     ]
    }
   ],
   "source": [
    "acc_combined = balanced_accuracy_score(results['Combined Prediction'], list(y_test))\n",
    "acc_t2 = balanced_accuracy_score(results['Prediction T2'], list(y_test))\n",
    "acc_q = balanced_accuracy_score(results['Prediction Q'], list(y_test))\n",
    "print(f'KS - hiPCA (T^2) : {acc_t2}')\n",
    "print(f'KS - hiPCA (Q) : {acc_q}')\n",
    "print(f'KS - hiPCA (Combined): {acc_combined}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f8005-52f8-4cfb-ac3a-ee7da9f76ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29fe6937-d624-4675-a8b0-e07ceff1a903",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea83af6-092a-4906-8fed-28d3b923eb14",
   "metadata": {},
   "source": [
    "Next, we will try using the species selected by the differential abundance test with p-value 0.05 and 0.005 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5581cfda-54dd-4acb-84ae-1bb711f06f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Principal Components selected: 25\n",
      "0.95 25\n",
      "37.65248413348277\n",
      "37.65248413348277 7.917922960056595 1.7726626649772614\n"
     ]
    }
   ],
   "source": [
    "features_ancom = pd.read_csv('../../DataSets/INDEX/hiPCA/ANCOM-BC_pvalue 0.05.txt', sep=\"\\t\")\n",
    "features, pca, pca_data, D, t2_threshold, C, Q_alpha, fi, threshold_combined, selected = hiPCA(X_train.T, healthy, non_healthy, ks = False, features=list(features_ancom['Species']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "bb53b60c-64ef-432a-87f3-c6ca5ac9b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = transform_data(X_test.T, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c1297297-686f-4876-96d4-8105532334a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = calculate_index(test_transformed)\n",
    "# results.to_csv('../../output/hiPCA/experiment3_results1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f78da686-f6fa-4f87-93ab-88fc594e6f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7474747474747475"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(results['Combined Prediction'], list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e7b8a8cb-cff8-4b90-b55b-ba1fa71046ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS - hiPCA (T^2) : 0.6850877192982456\n",
      "KS - hiPCA (Q) : 0.24\n",
      "KS - hiPCA (Combined): 0.7474747474747475\n"
     ]
    }
   ],
   "source": [
    "acc_combined = balanced_accuracy_score(results['Combined Prediction'], list(y_test))\n",
    "acc_t2 = balanced_accuracy_score(results['Prediction T2'], list(y_test))\n",
    "acc_q = balanced_accuracy_score(results['Prediction Q'], list(y_test))\n",
    "print(f'KS - hiPCA (T^2) : {acc_t2}')\n",
    "print(f'KS - hiPCA (Q) : {acc_q}')\n",
    "print(f'KS - hiPCA (Combined): {acc_combined}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7f988-5fa2-402f-87e0-0d0ee2c2542d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "bb3fa5b0-db20-479c-baaf-8a9accbdc8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Principal Components selected: 21\n",
      "0.95 21\n",
      "32.670573340917315\n",
      "32.670573340917315 6.70865917494215 1.7555456167236936\n"
     ]
    }
   ],
   "source": [
    "features_ancom = pd.read_csv('../../DataSets/INDEX/hiPCA/ANCOM-BC_pvalue 0.005.txt', sep=\"\\t\")\n",
    "features, pca, pca_data, D, t2_threshold, C, Q_alpha, fi, threshold_combined, selected = hiPCA(X_train.T, healthy, non_healthy, ks = False, features=list(features_ancom['Species']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e8760002-e99a-4b0d-a886-7c334d745553",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = transform_data(X_test.T, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0a590a3f-a66d-4585-9ee1-e6e2b4e793c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = calculate_index(test_transformed)\n",
    "# results.to_csv('../../output/hiPCA/experiment3_results2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "70ba5854-c099-4430-bf32-e8d1c0f07080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6443236714975846"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(results['Combined Prediction'], list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b7eb58bc-0bb4-487b-935b-c6f2905f3b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS - hiPCA (T^2) : 0.45274725274725275\n",
      "KS - hiPCA (Q) : 0.5807017543859649\n",
      "KS - hiPCA (Combined): 0.6443236714975846\n"
     ]
    }
   ],
   "source": [
    "acc_combined = balanced_accuracy_score(results['Combined Prediction'], list(y_test))\n",
    "acc_t2 = balanced_accuracy_score(results['Prediction T2'], list(y_test))\n",
    "acc_q = balanced_accuracy_score(results['Prediction Q'], list(y_test))\n",
    "print(f'KS - hiPCA (T^2) : {acc_t2}')\n",
    "print(f'KS - hiPCA (Q) : {acc_q}')\n",
    "print(f'KS - hiPCA (Combined): {acc_combined}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2615a92a-a87c-454f-92cc-82bc10b5f3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cf8b0f4-1343-479d-b102-15556a605331",
   "metadata": {},
   "source": [
    "### Experiment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad26e83-d3b4-4adb-8fa5-27ff630822b8",
   "metadata": {},
   "source": [
    "Now we are going to use the pathways to build the index, first we will build it with just the unhealthy related pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "453f6b19-1cb7-4b1b-873b-100f71bed016",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways = pd.read_csv('../../DataSets/CAMDA/pathways.txt', sep = '\\t', index_col = 0)\n",
    "pathways = pathways.T[[x for x in pathways.index if 'UNINTEGRATED' not in x]]\n",
    "pathways = pathways.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6176d8ea-3dc1-4ad6-90f8-43db17c1a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples = []\n",
    "for c in taxonomy.columns:\n",
    "    if sum(taxonomy[c]) > 90:\n",
    "        good_samples.append(c)\n",
    "pathways_aux = pathways[good_samples]\n",
    "\n",
    "ob = list(metadata[metadata['Diagnosis'] == 'Obese']['SampleID'])\n",
    "\n",
    "healthy = list(metadata[metadata['Diagnosis'] == 'Healthy']['SampleID'])\n",
    "non_healthy = list(metadata[metadata['Diagnosis'] != 'Healthy']['SampleID'])\n",
    "non_healthy = [x for x in non_healthy if x not in ob]\n",
    "\n",
    "pathways_healthy = pathways[[x for x in pathways_aux.columns if x in healthy]].T\n",
    "pathways_nonhealthy = pathways[[x for x in pathways_aux.columns if x in non_healthy]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f7cac4b5-9994-4756-ba6c-5b05e976efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for item in pathways_aux.columns:\n",
    "    if metadata[metadata['SampleID'] == item]['Diagnosis'].iloc[0] == 'Healthy':\n",
    "        label.append('Healthy')\n",
    "    else:\n",
    "        label.append('Unhealthy')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pathways_aux.T, label, test_size=0.20, random_state=20, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9dcd57ae-364f-4ab2-ad21-20134df7ce86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Healthy features selected by KS: 1016\n",
      "# Unheatlhy features selected by KS: 659\n",
      "# Principal Components selected: 9\n",
      "0.95 9\n",
      "16.918977604620448\n",
      "16.918977604620448 114.95910612152693 1.7160996201302054\n"
     ]
    }
   ],
   "source": [
    "features, pca, pca_data, D, t2_threshold, C, Q_alpha, fi, threshold_combined, selected = hiPCA(X_train.T, healthy, non_healthy, ks = True, only_nonhealthy_features = True, method = 'asymp', p_val = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a5c0d5d4-fd78-4311-8535-a186c0b284a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = transform_data(X_test.T, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "745b4b75-d52c-4bb5-8ea4-91ec67373759",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = calculate_index(test_transformed)\n",
    "# results.to_csv('../../output/hiPCA/experiment4_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0782efbb-5c8c-457e-9b40-ea1d038877bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095238095238095"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(results['Combined Prediction'], list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "841a0d64-8298-4391-93b8-f7b766a53572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS - hiPCA (T^2) : 0.7921348314606742\n",
      "KS - hiPCA (Q) : 0.7708333333333333\n",
      "KS - hiPCA (Combined): 0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "acc_combined = balanced_accuracy_score(results['Combined Prediction'], list(y_test))\n",
    "acc_t2 = balanced_accuracy_score(results['Prediction T2'], list(y_test))\n",
    "acc_q = balanced_accuracy_score(results['Prediction Q'], list(y_test))\n",
    "print(f'KS - hiPCA (T^2) : {acc_t2}')\n",
    "print(f'KS - hiPCA (Q) : {acc_q}')\n",
    "print(f'KS - hiPCA (Combined): {acc_combined}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63754073-c695-4b7f-9bdc-58fcdcb20779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3d4c29e-2a0d-4f1d-aa20-5cf9e4591201",
   "metadata": {},
   "source": [
    "### Experiment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd0b53e-98b8-43ce-886b-8272667d36e1",
   "metadata": {},
   "source": [
    "Now we will fit both the unhealthy and healthy related pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "88cde101-50a2-4672-9f8b-2de249547403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Healthy features selected by KS: 1016\n",
      "# Unheatlhy features selected by KS: 659\n",
      "# Principal Components selected: 26\n",
      "0.95 26\n",
      "38.885138659830055\n",
      "38.885138659830055 118.03589503853675 2.7801519279115507\n"
     ]
    }
   ],
   "source": [
    "features, pca, pca_data, D, t2_threshold, C, Q_alpha, fi, threshold_combined, selected = hiPCA(X_train.T, healthy, non_healthy, ks = True, only_nonhealthy_features = False, method = 'asymp', p_val = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1eda10c7-01f6-4bd5-b393-b2fd15d75986",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = transform_data(X_test.T, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "69b430eb-5a7c-4fb4-afb5-63235f256a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = calculate_index(test_transformed)\n",
    "# results.to_csv('../../output/hiPCA/experiment5_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0b8d4e5b-03be-49e8-8d05-e5ab56c0d339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7357549857549857"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(results['Combined Prediction'], list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "07c4454c-6ec2-4047-8cc3-ac29eef80ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS - hiPCA (T^2) : 0.6480562448304383\n",
      "KS - hiPCA (Q) : 0.6670020120724346\n",
      "KS - hiPCA (Combined): 0.7357549857549857\n"
     ]
    }
   ],
   "source": [
    "acc_combined = balanced_accuracy_score(results['Combined Prediction'], list(y_test))\n",
    "acc_t2 = balanced_accuracy_score(results['Prediction T2'], list(y_test))\n",
    "acc_q = balanced_accuracy_score(results['Prediction Q'], list(y_test))\n",
    "print(f'KS - hiPCA (T^2) : {acc_t2}')\n",
    "print(f'KS - hiPCA (Q) : {acc_q}')\n",
    "print(f'KS - hiPCA (Combined): {acc_combined}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c71ee2-2d5c-4d5f-8e65-e62ee761e602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e531a951-33e1-4df4-9f5c-8c4f611cd77e",
   "metadata": {},
   "source": [
    "### Experiment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5d2b5-3a54-4391-9bc3-ccc53daa9447",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "d1e40a1b-4e9d-46c1-864e-e9635b8479fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for item in taxonomy_transposed.T.columns:\n",
    "    if metadata[metadata['SampleID'] == item]['Diagnosis'].iloc[0] == 'Healthy':\n",
    "        label.append('Healthy')\n",
    "    else:\n",
    "        label.append('Unhealthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "ecb6b6b1-c821-4d72-a626-d74bf2c142ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(taxonomy_transposed, label, test_size=0.20, random_state=20, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "15ff089b-b4c1-4722-80d7-4d2c289fd414",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways = pd.read_csv('../../DataSets/CAMDA/pathways.txt', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "803e8b5f-ad45-4941-9c53-4fb975ba1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_train = pathways[list(X_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "1d291d9d-8df5-489a-bd8b-0276bcd085ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_train = pathways_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "2caad5e4-e230-463d-b1a0-1c0f4e0b2ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "27e6a6d6-2917-45ef-9247-d96027717370",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=10, min_samples_leaf=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "b4358c79-f31f-40da-9ff8-052bb37284ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=3, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=3, random_state=0)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(pathways_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "56076dad-bbef-4d8e-9064-28dd57604112",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pathways = list(pd.DataFrame(zip(pathways_train.columns, clf.feature_importances_)).sort_values(1, ascending = False)[:89][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "4dca70ab-a38f-4f46-ac29-0359bd31583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pathways_train[selected_pathways]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "cdb397b7-6622-4ad1-94e7-81d1a3d6d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('../../output/hiPCA/experiment1_results_train.csv')\n",
    "results2 = pd.read_csv('../../output/hiPCA/experiment1_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "ce193be0-6aeb-4f7c-9f27-a79eecce73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected['hiPCA'] = list(results['Combined Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "b3024d2d-1ec7-4732-907d-ad59549c27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected['hiPCA'] = selected['hiPCA'] - 1.69 #Threshold combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "c13f072f-52a2-444e-bae9-8cdffae0f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_test = pathways.T[selected_pathways]\n",
    "pathways_test = pathways_test.T[X_test.index].T\n",
    "pathways_test['hiPCA'] = list(results2['Combined Index'])\n",
    "pathways_test['hiPCA'] = pathways_test['hiPCA'] - 1.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "5e735616-3382-4e63-9f0f-5e983d9c5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "8eb36bc6-8262-4ea5-89b2-4df3f5201b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "for c in selected.columns:\n",
    "    scaler.fit(np.array(selected[c]).reshape(-1, 1))\n",
    "    selected[c] = scaler.transform(np.array(selected[c]).reshape(-1, 1))\n",
    "    pathways_test[c] = scaler.transform(np.array(pathways_test[c]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "33d66ed8-5425-4093-aba4-726d4fb8455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "6178e0d9-e308-4856-b3a5-b721bf90f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "030bed26-44d7-4a63-9d9a-111632ac816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(zip(list(selected.columns), clf.coef_[0]), columns = ['Features', 'Coeficient']).sort_values('Coeficient', ascending  = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "1ac814c8-b80d-434d-bbdc-4a6fa240ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.to_csv('../../output/hiPCA/coefficients_logreg.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "0635a915-25fb-4e70-b0ad-342e44e8ed73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8198587127158555"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(pathways_test)\n",
    "balanced_accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d1688-b44f-402b-bed3-1aad1eb2b243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "b113ea5d-6512-4e2e-9600-1eb05f8aeda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8498822605965464"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=10, min_samples_leaf=3, random_state=0)\n",
    "clf.fit(selected, y_train)\n",
    "pred = clf.predict(pathways_test)\n",
    "balanced_accuracy_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
